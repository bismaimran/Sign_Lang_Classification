{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## IMPORTING LIBRARIES","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LOADING THE DATASET","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv')\ntest=pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PREPROCESSING AND VISUALIZING THE DATASET","metadata":{}},{"cell_type":"code","source":"#Datasets as numpy arrays\ntrain_data = np.array(train, dtype = 'float32')\ntest_data = np.array(test, dtype='float32')\n\n#Define class labels for easy interpretation\nclass_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', \n               'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y' ]\n\n#Sanity check - plot an image and label\ni = random.randint(1,train.shape[0])\nfig1, ax1 = plt.subplots(figsize=(2,2))\nplt.imshow(train_data[i,1:].reshape((28,28)), cmap='gray') \nprint(\"Label for the image is: \", class_names[int(train_data[i,0])])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data distribution visualization\nfig = plt.figure(figsize=(18,18))\nax1 = fig.add_subplot(221)\ntrain['label'].value_counts().plot(kind='bar', ax=ax1)\nax1.set_ylabel('Count')\nax1.set_title('Label')\n\n#Dataset seems to be fairly balanced.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalize / scale X values\nX_train = train_data[:, 1:] /255.\nX_test = test_data[:, 1:] /255.\n\n#Convert y to categorical if planning on using categorical cross entropy\ny_train = train_data[:, 0]\ny_train_cat = to_categorical(y_train, num_classes=25)\n\ny_test = test_data[:,0]\ny_test_cat = to_categorical(y_test, num_classes=25)\n\n#Reshape for the neural network\nX_train = X_train.reshape(X_train.shape[0], *(28, 28, 1))\nX_test = X_test.reshape(X_test.shape[0], *(28, 28, 1))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CREATING AND TRAINING THE MODEL","metadata":{}},{"cell_type":"code","source":"#Model\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), input_shape = (28,28,1), activation='relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\n\n\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(25, activation = 'softmax'))\n\n\n#If your targets are one-hot encoded, use categorical_crossentropy. Examples of one-hot encodings:\n# If your targets are integers, use sparse_categorical_crossentropy. \n\nmodel.compile(loss ='categorical_crossentropy', optimizer='adam', metrics =['acc'])\nmodel.summary()\n\n\nhistory = model.fit(X_train, y_train_cat, batch_size = 128, epochs = 10, verbose = 1, validation_data = (X_test, y_test_cat))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PLOTTING THE TARINING AND VALIDATION ACCURACY AND LOSS","metadata":{}},{"cell_type":"code","source":"#plot the training and validation accuracy and loss at each epoch\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\nplt.plot(epochs, acc, 'y', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PREDICTING THE CLASS LABELS","metadata":{}},{"cell_type":"code","source":"prediction = model.predict(X_test)\ny_pred = np.argmax(prediction, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PLOTTING PREDICTION WITH TRUE AND PREDICTED LABEL AND CHECKING ACCURACY","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy Score = ', accuracy)\n\ni = random.randint(1,len(y_pred))\nfig1, ax1 = plt.subplots(figsize=(2,2))\nplt.imshow(X_test[i,:,:,0]) \nprint(\"Predicted Label: \", class_names[int(y_pred[i])])\nprint(\"True Label: \", class_names[int(y_test[i])])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PLOTTING CONFUSION MATRIX","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n#Print confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\nfig, ax = plt.subplots(figsize=(12,12))\nsns.set(font_scale=1.6)\nsns.heatmap(cm, annot=True, linewidths=.5, ax=ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PLOTTING FRACTIONAL INCORRECT MISCLASSIFICATION","metadata":{}},{"cell_type":"code","source":"#PLot fractional incorrect misclassifications\nincorr_fraction = 1 - np.diag(cm) / np.sum(cm, axis=1)\nfig, ax = plt.subplots(figsize=(8,8))\nplt.bar(np.arange(24), incorr_fraction)\nplt.xlabel('True Label')\nplt.ylabel('Fraction of incorrect predictions')\nplt.xticks(np.arange(25), class_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}